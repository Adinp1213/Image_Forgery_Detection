{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from keras import layers, models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'D:/IMAGE_FORGERY_DATASET/Dataset'\n",
    "forged_path = r'D:/IMAGE_FORGERY_DATASET/Dataset/Forged'\n",
    "real_path = r'D:/IMAGE_FORGERY_DATASET/Dataset/Original'\n",
    "img_height, img_width = 128,128\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.67058825 0.41568628 0.21568628]\n",
      "   [0.6745098  0.41960785 0.21960784]\n",
      "   [0.6784314  0.42352942 0.22352941]\n",
      "   ...\n",
      "   [0.64705884 0.5019608  0.33333334]\n",
      "   [0.64705884 0.5058824  0.34901962]\n",
      "   [0.69411767 0.5529412  0.40392157]]\n",
      "\n",
      "  [[0.6666667  0.4117647  0.21176471]\n",
      "   [0.6745098  0.41960785 0.21960784]\n",
      "   [0.6784314  0.42352942 0.22352941]\n",
      "   ...\n",
      "   [0.6627451  0.52156866 0.3529412 ]\n",
      "   [0.6627451  0.5254902  0.37254903]\n",
      "   [0.68235296 0.54509807 0.39215687]]\n",
      "\n",
      "  [[0.6627451  0.40784314 0.20784314]\n",
      "   [0.6666667  0.4117647  0.21176471]\n",
      "   [0.6745098  0.41960785 0.21960784]\n",
      "   ...\n",
      "   [0.6784314  0.5372549  0.38039216]\n",
      "   [0.7058824  0.5686275  0.41568628]\n",
      "   [0.6862745  0.5568628  0.40784314]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.14901961 0.28235295 0.12156863]\n",
      "   [0.14901961 0.28235295 0.12156863]\n",
      "   [0.09019608 0.22352941 0.06666667]\n",
      "   ...\n",
      "   [0.15294118 0.2509804  0.11764706]\n",
      "   [0.13725491 0.23529412 0.10196079]\n",
      "   [0.12941177 0.22745098 0.09411765]]\n",
      "\n",
      "  [[0.14117648 0.27450982 0.11372549]\n",
      "   [0.14901961 0.28235295 0.12156863]\n",
      "   [0.13333334 0.26666668 0.10588235]\n",
      "   ...\n",
      "   [0.11764706 0.21568628 0.08235294]\n",
      "   [0.13333334 0.23137255 0.09803922]\n",
      "   [0.13333334 0.23137255 0.09803922]]\n",
      "\n",
      "  [[0.08627451 0.21960784 0.05882353]\n",
      "   [0.1254902  0.25882354 0.09803922]\n",
      "   [0.10980392 0.24313726 0.08235294]\n",
      "   ...\n",
      "   [0.1254902  0.22352941 0.09019608]\n",
      "   [0.10588235 0.20392157 0.07058824]\n",
      "   [0.09411765 0.19215687 0.05882353]]]\n",
      "\n",
      "\n",
      " [[[0.63529414 0.61960787 0.6       ]\n",
      "   [0.63529414 0.61960787 0.6       ]\n",
      "   [0.63529414 0.61960787 0.6       ]\n",
      "   ...\n",
      "   [0.61960787 0.6156863  0.56078434]\n",
      "   [0.61960787 0.6156863  0.56078434]\n",
      "   [0.61960787 0.6156863  0.56078434]]\n",
      "\n",
      "  [[0.63529414 0.61960787 0.6       ]\n",
      "   [0.63529414 0.61960787 0.6       ]\n",
      "   [0.63529414 0.61960787 0.6       ]\n",
      "   ...\n",
      "   [0.61960787 0.6156863  0.56078434]\n",
      "   [0.61960787 0.6156863  0.56078434]\n",
      "   [0.61960787 0.6156863  0.56078434]]\n",
      "\n",
      "  [[0.63529414 0.61960787 0.6       ]\n",
      "   [0.63529414 0.61960787 0.6       ]\n",
      "   [0.63529414 0.61960787 0.6       ]\n",
      "   ...\n",
      "   [0.61960787 0.6156863  0.56078434]\n",
      "   [0.61960787 0.6156863  0.56078434]\n",
      "   [0.61960787 0.6156863  0.56078434]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10980392 0.10980392 0.10980392]\n",
      "   [0.15686275 0.16078432 0.15294118]\n",
      "   [0.16078432 0.16470589 0.15686275]\n",
      "   ...\n",
      "   [0.43137255 0.4509804  0.44705883]\n",
      "   [0.43137255 0.4509804  0.44705883]\n",
      "   [0.42352942 0.44313726 0.4392157 ]]\n",
      "\n",
      "  [[0.11372549 0.10588235 0.10196079]\n",
      "   [0.13725491 0.14117648 0.13333334]\n",
      "   [0.13333334 0.13725491 0.12941177]\n",
      "   ...\n",
      "   [0.4862745  0.5058824  0.5019608 ]\n",
      "   [0.4862745  0.5058824  0.5019608 ]\n",
      "   [0.47843137 0.49803922 0.49411765]]\n",
      "\n",
      "  [[0.10980392 0.10196079 0.09803922]\n",
      "   [0.11372549 0.10588235 0.10196079]\n",
      "   [0.07843138 0.08235294 0.06666667]\n",
      "   ...\n",
      "   [0.47058824 0.49019608 0.4862745 ]\n",
      "   [0.46666667 0.4862745  0.48235294]\n",
      "   [0.4627451  0.48235294 0.47843137]]]\n",
      "\n",
      "\n",
      " [[[0.9529412  0.8784314  0.84705883]\n",
      "   [0.9529412  0.8784314  0.84705883]\n",
      "   [0.9529412  0.8784314  0.84705883]\n",
      "   ...\n",
      "   [0.9647059  0.88235295 0.8509804 ]\n",
      "   [0.9607843  0.8784314  0.84705883]\n",
      "   [0.9607843  0.8784314  0.84705883]]\n",
      "\n",
      "  [[0.9529412  0.8784314  0.84705883]\n",
      "   [0.9529412  0.8784314  0.84705883]\n",
      "   [0.9529412  0.8784314  0.84705883]\n",
      "   ...\n",
      "   [0.9607843  0.8784314  0.84705883]\n",
      "   [0.9607843  0.8784314  0.84705883]\n",
      "   [0.9607843  0.8784314  0.84705883]]\n",
      "\n",
      "  [[0.9529412  0.8784314  0.84705883]\n",
      "   [0.9529412  0.8784314  0.84705883]\n",
      "   [0.9529412  0.8784314  0.84705883]\n",
      "   ...\n",
      "   [0.9607843  0.8784314  0.84705883]\n",
      "   [0.95686275 0.8745098  0.84313726]\n",
      "   [0.95686275 0.8745098  0.84313726]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5411765  0.64705884 0.7019608 ]\n",
      "   [0.5411765  0.6392157  0.7019608 ]\n",
      "   [0.5176471  0.58431375 0.6666667 ]\n",
      "   ...\n",
      "   [0.6156863  0.654902   0.7490196 ]\n",
      "   [0.6156863  0.6392157  0.7529412 ]\n",
      "   [0.6313726  0.6627451  0.78039217]]\n",
      "\n",
      "  [[0.54509807 0.6627451  0.7372549 ]\n",
      "   [0.52156866 0.627451   0.70980394]\n",
      "   [0.44313726 0.5137255  0.627451  ]\n",
      "   ...\n",
      "   [0.58431375 0.627451   0.7372549 ]\n",
      "   [0.5529412  0.5803922  0.70980394]\n",
      "   [0.5764706  0.6117647  0.7411765 ]]\n",
      "\n",
      "  [[0.4        0.52156866 0.6117647 ]\n",
      "   [0.4117647  0.5176471  0.61960787]\n",
      "   [0.36862746 0.44313726 0.57254905]\n",
      "   ...\n",
      "   [0.50980395 0.54901963 0.6666667 ]\n",
      "   [0.4509804  0.4862745  0.6156863 ]\n",
      "   [0.49803922 0.53333336 0.6666667 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.827451   0.79607844 0.7294118 ]\n",
      "   [0.85490197 0.8235294  0.75686276]\n",
      "   [0.8784314  0.84705883 0.78039217]\n",
      "   ...\n",
      "   [0.0627451  0.14901961 0.10196079]\n",
      "   [0.02745098 0.10588235 0.05882353]\n",
      "   [0.09803922 0.16470589 0.12156863]]\n",
      "\n",
      "  [[0.827451   0.79607844 0.7294118 ]\n",
      "   [0.8392157  0.80784315 0.7411765 ]\n",
      "   [0.84313726 0.8117647  0.74509805]\n",
      "   ...\n",
      "   [0.01960784 0.10588235 0.05882353]\n",
      "   [0.15686275 0.22352941 0.18039216]\n",
      "   [0.21568628 0.28235295 0.23921569]]\n",
      "\n",
      "  [[0.5764706  0.54509807 0.47843137]\n",
      "   [0.654902   0.62352943 0.5568628 ]\n",
      "   [0.7607843  0.7294118  0.6627451 ]\n",
      "   ...\n",
      "   [0.12941177 0.21568628 0.16862746]\n",
      "   [0.3647059  0.43137255 0.3882353 ]\n",
      "   [0.20392157 0.26666668 0.22352941]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10196079 0.22352941 0.1882353 ]\n",
      "   [0.14901961 0.28235295 0.23921569]\n",
      "   [0.17254902 0.32156864 0.27450982]\n",
      "   ...\n",
      "   [0.03921569 0.11372549 0.07843138]\n",
      "   [0.04705882 0.11372549 0.07058824]\n",
      "   [0.03529412 0.10588235 0.05490196]]\n",
      "\n",
      "  [[0.21568628 0.2901961  0.25490198]\n",
      "   [0.22352941 0.30980393 0.2627451 ]\n",
      "   [0.21176471 0.3137255  0.2627451 ]\n",
      "   ...\n",
      "   [0.05098039 0.1254902  0.09019608]\n",
      "   [0.04705882 0.12156863 0.08627451]\n",
      "   [0.01960784 0.09803922 0.05098039]]\n",
      "\n",
      "  [[0.35686275 0.4117647  0.36862746]\n",
      "   [0.3254902  0.3882353  0.34509805]\n",
      "   [0.2627451  0.34117648 0.29411766]\n",
      "   ...\n",
      "   [0.08235294 0.16470589 0.13333334]\n",
      "   [0.09803922 0.17254902 0.13725491]\n",
      "   [0.0627451  0.13725491 0.10196079]]]\n",
      "\n",
      "\n",
      " [[[0.08627451 0.16078432 0.21176471]\n",
      "   [0.09019608 0.16470589 0.21568628]\n",
      "   [0.11372549 0.1764706  0.22352941]\n",
      "   ...\n",
      "   [0.93333334 0.8980392  0.84705883]\n",
      "   [1.         0.9882353  0.9607843 ]\n",
      "   [0.9764706  0.9137255  0.8862745 ]]\n",
      "\n",
      "  [[0.09019608 0.16470589 0.21568628]\n",
      "   [0.10196079 0.1764706  0.22745098]\n",
      "   [0.11764706 0.18039216 0.22745098]\n",
      "   ...\n",
      "   [0.89411765 0.84705883 0.8       ]\n",
      "   [1.         0.9647059  0.92941177]\n",
      "   [1.         0.9529412  0.9254902 ]]\n",
      "\n",
      "  [[0.09803922 0.17254902 0.22352941]\n",
      "   [0.11764706 0.19215687 0.24313726]\n",
      "   [0.1254902  0.1882353  0.23529412]\n",
      "   ...\n",
      "   [0.8509804  0.8039216  0.75686276]\n",
      "   [0.972549   0.9137255  0.8784314 ]\n",
      "   [1.         0.9607843  0.93333334]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.01960784 0.07058824 0.0627451 ]\n",
      "   [0.01568628 0.06666667 0.05882353]\n",
      "   [0.00784314 0.05882353 0.05098039]\n",
      "   ...\n",
      "   [0.7882353  0.49019608 0.01960784]\n",
      "   [0.78431374 0.4862745  0.01568628]\n",
      "   [0.78431374 0.47843137 0.00784314]]\n",
      "\n",
      "  [[0.01960784 0.07058824 0.0627451 ]\n",
      "   [0.00784314 0.05882353 0.05098039]\n",
      "   [0.         0.05098039 0.04313726]\n",
      "   ...\n",
      "   [0.8117647  0.49803922 0.05490196]\n",
      "   [0.8039216  0.4862745  0.03529412]\n",
      "   [0.79607844 0.47843137 0.02745098]]\n",
      "\n",
      "  [[0.01176471 0.0627451  0.05490196]\n",
      "   [0.         0.05098039 0.04313726]\n",
      "   [0.         0.03921569 0.03137255]\n",
      "   ...\n",
      "   [0.7921569  0.4745098  0.03921569]\n",
      "   [0.8        0.47058824 0.03137255]\n",
      "   [0.79607844 0.46666667 0.02745098]]]\n",
      "\n",
      "\n",
      " [[[0.03529412 0.15294118 0.10980392]\n",
      "   [0.04313726 0.16078432 0.11764706]\n",
      "   [0.05490196 0.17254902 0.12941177]\n",
      "   ...\n",
      "   [0.05882353 0.11372549 0.09803922]\n",
      "   [0.05490196 0.10980392 0.09411765]\n",
      "   [0.05098039 0.10588235 0.09019608]]\n",
      "\n",
      "  [[0.02352941 0.14117648 0.09803922]\n",
      "   [0.05098039 0.16862746 0.1254902 ]\n",
      "   [0.07843138 0.19607843 0.15294118]\n",
      "   ...\n",
      "   [0.05490196 0.10980392 0.09411765]\n",
      "   [0.05490196 0.10980392 0.09411765]\n",
      "   [0.05098039 0.10588235 0.09019608]]\n",
      "\n",
      "  [[0.05098039 0.16470589 0.12941177]\n",
      "   [0.06666667 0.18039216 0.14509805]\n",
      "   [0.08235294 0.19607843 0.16078432]\n",
      "   ...\n",
      "   [0.0627451  0.10588235 0.09411765]\n",
      "   [0.05490196 0.10980392 0.09411765]\n",
      "   [0.05098039 0.10588235 0.09019608]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.31764707 0.45490196 0.47058824]\n",
      "   [0.31764707 0.45490196 0.47058824]\n",
      "   [0.34117648 0.47843137 0.49411765]\n",
      "   ...\n",
      "   [0.3647059  0.39215687 0.46666667]\n",
      "   [0.34509805 0.37254903 0.4509804 ]\n",
      "   [0.31764707 0.34509805 0.42352942]]\n",
      "\n",
      "  [[0.23529412 0.37254903 0.3882353 ]\n",
      "   [0.30588236 0.44313726 0.45882353]\n",
      "   [0.32156864 0.45882353 0.4745098 ]\n",
      "   ...\n",
      "   [0.36078432 0.3882353  0.4627451 ]\n",
      "   [0.35686275 0.38431373 0.4627451 ]\n",
      "   [0.34117648 0.36862746 0.44705883]]\n",
      "\n",
      "  [[0.22745098 0.3647059  0.38039216]\n",
      "   [0.34117648 0.47843137 0.49411765]\n",
      "   [0.32941177 0.46666667 0.48235294]\n",
      "   ...\n",
      "   [0.34509805 0.37254903 0.44705883]\n",
      "   [0.34901962 0.3764706  0.45490196]\n",
      "   [0.34509805 0.37254903 0.4509804 ]]]] [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_directory_real(directory, target_size=(img_height, img_width)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        path = os.path.join(directory, filename)\n",
    "        label = 1 \n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        img = img.astype('float32') / 255.0\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "real_images,real_labels = load_images_from_directory_real(real_path, target_size=(img_height, img_width))\n",
    "print(real_images,real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.7882353  0.6745098  0.5921569 ]\n",
      "   [0.7882353  0.6745098  0.5921569 ]\n",
      "   [0.7882353  0.6745098  0.5921569 ]\n",
      "   ...\n",
      "   [0.6313726  0.5411765  0.4745098 ]\n",
      "   [0.59607846 0.5019608  0.4509804 ]\n",
      "   [0.58431375 0.48235294 0.44705883]]\n",
      "\n",
      "  [[0.7921569  0.6784314  0.59607846]\n",
      "   [0.7921569  0.6784314  0.59607846]\n",
      "   [0.7921569  0.6784314  0.59607846]\n",
      "   ...\n",
      "   [0.6431373  0.54509807 0.47843137]\n",
      "   [0.5686275  0.47058824 0.41568628]\n",
      "   [0.5921569  0.49019608 0.44705883]]\n",
      "\n",
      "  [[0.8        0.6862745  0.6039216 ]\n",
      "   [0.79607844 0.68235296 0.6       ]\n",
      "   [0.79607844 0.68235296 0.6       ]\n",
      "   ...\n",
      "   [0.5176471  0.41960785 0.3529412 ]\n",
      "   [0.5254902  0.42352942 0.36078432]\n",
      "   [0.6        0.5019608  0.4392157 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7176471  0.6392157  0.61960787]\n",
      "   [0.654902   0.5764706  0.5568628 ]\n",
      "   [0.7372549  0.65882355 0.6392157 ]\n",
      "   ...\n",
      "   [0.9764706  0.93333334 0.9411765 ]\n",
      "   [0.98039216 0.9372549  0.94509804]\n",
      "   [0.9764706  0.93333334 0.9411765 ]]\n",
      "\n",
      "  [[0.81960785 0.7411765  0.72156864]\n",
      "   [0.74509805 0.6666667  0.64705884]\n",
      "   [0.78039217 0.7019608  0.68235296]\n",
      "   ...\n",
      "   [0.9607843  0.91764706 0.9254902 ]\n",
      "   [0.9607843  0.91764706 0.9254902 ]\n",
      "   [0.972549   0.92941177 0.9372549 ]]\n",
      "\n",
      "  [[0.80784315 0.7294118  0.70980394]\n",
      "   [0.7882353  0.70980394 0.6901961 ]\n",
      "   [0.9137255  0.8352941  0.8156863 ]\n",
      "   ...\n",
      "   [0.95686275 0.9137255  0.92156863]\n",
      "   [0.9529412  0.9098039  0.91764706]\n",
      "   [0.95686275 0.9137255  0.92156863]]]\n",
      "\n",
      "\n",
      " [[[0.7058824  0.5058824  0.34901962]\n",
      "   [0.7058824  0.5058824  0.34901962]\n",
      "   [0.7058824  0.5058824  0.34901962]\n",
      "   ...\n",
      "   [0.56078434 0.3529412  0.12941177]\n",
      "   [0.56078434 0.3529412  0.12941177]\n",
      "   [0.56078434 0.3529412  0.12941177]]\n",
      "\n",
      "  [[0.7058824  0.5058824  0.34901962]\n",
      "   [0.7058824  0.5058824  0.34901962]\n",
      "   [0.7058824  0.5058824  0.34901962]\n",
      "   ...\n",
      "   [0.5647059  0.35686275 0.13333334]\n",
      "   [0.5647059  0.35686275 0.13333334]\n",
      "   [0.5647059  0.35686275 0.13333334]]\n",
      "\n",
      "  [[0.7058824  0.5058824  0.34901962]\n",
      "   [0.7058824  0.5058824  0.34901962]\n",
      "   [0.7058824  0.5058824  0.34901962]\n",
      "   ...\n",
      "   [0.5686275  0.36078432 0.13725491]\n",
      "   [0.5686275  0.36078432 0.13725491]\n",
      "   [0.5686275  0.36078432 0.13725491]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8980392  0.8392157  0.8039216 ]\n",
      "   [0.8980392  0.8392157  0.8039216 ]\n",
      "   [0.9019608  0.84313726 0.80784315]\n",
      "   ...\n",
      "   [0.8745098  0.8        0.76862746]\n",
      "   [0.8627451  0.7882353  0.75686276]\n",
      "   [0.8745098  0.8        0.76862746]]\n",
      "\n",
      "  [[0.9098039  0.8509804  0.8156863 ]\n",
      "   [0.9019608  0.84313726 0.80784315]\n",
      "   [0.89411765 0.8352941  0.8       ]\n",
      "   ...\n",
      "   [0.8627451  0.7882353  0.75686276]\n",
      "   [0.87058824 0.79607844 0.7647059 ]\n",
      "   [0.8666667  0.7921569  0.7607843 ]]\n",
      "\n",
      "  [[0.9098039  0.8509804  0.8156863 ]\n",
      "   [0.9137255  0.85490197 0.81960785]\n",
      "   [0.9019608  0.84313726 0.80784315]\n",
      "   ...\n",
      "   [0.8862745  0.8117647  0.78039217]\n",
      "   [0.8745098  0.8        0.76862746]\n",
      "   [0.8784314  0.8039216  0.77254903]]]\n",
      "\n",
      "\n",
      " [[[0.28627452 0.21960784 0.        ]\n",
      "   [0.28627452 0.21960784 0.        ]\n",
      "   [0.28627452 0.21960784 0.        ]\n",
      "   ...\n",
      "   [0.28627452 0.21568628 0.00784314]\n",
      "   [0.28627452 0.21568628 0.00784314]\n",
      "   [0.28627452 0.21568628 0.00784314]]\n",
      "\n",
      "  [[0.28627452 0.21960784 0.        ]\n",
      "   [0.28627452 0.21960784 0.        ]\n",
      "   [0.28627452 0.21960784 0.        ]\n",
      "   ...\n",
      "   [0.28627452 0.21568628 0.00784314]\n",
      "   [0.28627452 0.21568628 0.00784314]\n",
      "   [0.28627452 0.21568628 0.00784314]]\n",
      "\n",
      "  [[0.28627452 0.21960784 0.        ]\n",
      "   [0.28627452 0.21960784 0.        ]\n",
      "   [0.28627452 0.21960784 0.        ]\n",
      "   ...\n",
      "   [0.28627452 0.21568628 0.00784314]\n",
      "   [0.28627452 0.21568628 0.00784314]\n",
      "   [0.28627452 0.21568628 0.00784314]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.19607843 0.34117648 0.21568628]\n",
      "   [0.14901961 0.31764707 0.18431373]\n",
      "   [0.16078432 0.3647059  0.21960784]\n",
      "   ...\n",
      "   [0.11372549 0.33333334 0.17254902]\n",
      "   [0.10588235 0.32941177 0.16470589]\n",
      "   [0.13725491 0.36078432 0.2       ]]\n",
      "\n",
      "  [[0.2627451  0.41568628 0.29411766]\n",
      "   [0.14509805 0.32941177 0.19215687]\n",
      "   [0.12156863 0.34117648 0.18431373]\n",
      "   ...\n",
      "   [0.10196079 0.32156864 0.16078432]\n",
      "   [0.05882353 0.2784314  0.11764706]\n",
      "   [0.09019608 0.30980393 0.14901961]]\n",
      "\n",
      "  [[0.14901961 0.30980393 0.18039216]\n",
      "   [0.14117648 0.32941177 0.1882353 ]\n",
      "   [0.11372549 0.3372549  0.18039216]\n",
      "   ...\n",
      "   [0.01568628 0.21568628 0.05490196]\n",
      "   [0.04313726 0.25490198 0.09411765]\n",
      "   [0.02745098 0.22745098 0.07058824]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.7607843  0.5647059  0.3372549 ]\n",
      "   [0.7647059  0.5686275  0.34117648]\n",
      "   [0.7607843  0.5647059  0.3372549 ]\n",
      "   ...\n",
      "   [0.6627451  0.46666667 0.23137255]\n",
      "   [0.6627451  0.46666667 0.23137255]\n",
      "   [0.6666667  0.47058824 0.23529412]]\n",
      "\n",
      "  [[0.7607843  0.5647059  0.3372549 ]\n",
      "   [0.7607843  0.5647059  0.3372549 ]\n",
      "   [0.7607843  0.5647059  0.3372549 ]\n",
      "   ...\n",
      "   [0.6666667  0.47058824 0.23529412]\n",
      "   [0.65882355 0.4627451  0.22745098]\n",
      "   [0.654902   0.45882353 0.22352941]]\n",
      "\n",
      "  [[0.7607843  0.5647059  0.3372549 ]\n",
      "   [0.7607843  0.5647059  0.3372549 ]\n",
      "   [0.7607843  0.5647059  0.3372549 ]\n",
      "   ...\n",
      "   [0.65882355 0.4627451  0.22745098]\n",
      "   [0.67058825 0.4745098  0.23921569]\n",
      "   [0.6784314  0.48235294 0.24705882]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.21568628 0.19215687 0.2       ]\n",
      "   [0.22352941 0.20392157 0.21568628]\n",
      "   [0.35686275 0.33333334 0.34901962]\n",
      "   ...\n",
      "   [0.18431373 0.35686275 0.25882354]\n",
      "   [0.23529412 0.39607844 0.23529412]\n",
      "   [0.3137255  0.41960785 0.28627452]]\n",
      "\n",
      "  [[0.25882354 0.24705882 0.24705882]\n",
      "   [0.20392157 0.19607843 0.19607843]\n",
      "   [0.28627452 0.27450982 0.28235295]\n",
      "   ...\n",
      "   [0.08627451 0.19215687 0.09019608]\n",
      "   [0.16862746 0.29803923 0.13333334]\n",
      "   [0.2784314  0.4        0.25882354]]\n",
      "\n",
      "  [[0.21960784 0.25490198 0.20392157]\n",
      "   [0.28235295 0.31764707 0.27450982]\n",
      "   [0.38431373 0.41568628 0.38039216]\n",
      "   ...\n",
      "   [0.13333334 0.21176471 0.10196079]\n",
      "   [0.12941177 0.2627451  0.09411765]\n",
      "   [0.23137255 0.3882353  0.23921569]]]\n",
      "\n",
      "\n",
      " [[[0.6784314  0.64705884 0.6862745 ]\n",
      "   [0.67058825 0.6431373  0.68235296]\n",
      "   [0.67058825 0.654902   0.69803923]\n",
      "   ...\n",
      "   [0.7058824  0.79607844 0.96862745]\n",
      "   [0.7647059  0.8862745  1.        ]\n",
      "   [0.4862745  0.5529412  0.6627451 ]]\n",
      "\n",
      "  [[0.6745098  0.6431373  0.68235296]\n",
      "   [0.67058825 0.6392157  0.68235296]\n",
      "   [0.6666667  0.6509804  0.69803923]\n",
      "   ...\n",
      "   [0.7254902  0.8156863  0.9843137 ]\n",
      "   [0.7764706  0.8980392  1.        ]\n",
      "   [0.47843137 0.54901963 0.65882355]]\n",
      "\n",
      "  [[0.67058825 0.6392157  0.6784314 ]\n",
      "   [0.6666667  0.63529414 0.6784314 ]\n",
      "   [0.6666667  0.64705884 0.69411767]\n",
      "   ...\n",
      "   [0.70980394 0.8117647  0.972549  ]\n",
      "   [0.7647059  0.89411765 1.        ]\n",
      "   [0.46666667 0.5372549  0.64705884]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5372549  0.50980395 0.48235294]\n",
      "   [0.5529412  0.52156866 0.5058824 ]\n",
      "   [0.5529412  0.53333336 0.5176471 ]\n",
      "   ...\n",
      "   [0.14901961 0.23529412 0.25882354]\n",
      "   [0.16862746 0.25882354 0.28235295]\n",
      "   [0.10980392 0.15294118 0.17254902]]\n",
      "\n",
      "  [[0.5372549  0.5058824  0.48235294]\n",
      "   [0.50980395 0.47843137 0.4627451 ]\n",
      "   [0.5137255  0.49411765 0.47843137]\n",
      "   ...\n",
      "   [0.15294118 0.23921569 0.2627451 ]\n",
      "   [0.16862746 0.25882354 0.28627452]\n",
      "   [0.12156863 0.16470589 0.18431373]]\n",
      "\n",
      "  [[0.54509807 0.5137255  0.4862745 ]\n",
      "   [0.5294118  0.49803922 0.47843137]\n",
      "   [0.56078434 0.5411765  0.5254902 ]\n",
      "   ...\n",
      "   [0.1764706  0.2627451  0.28627452]\n",
      "   [0.1882353  0.2784314  0.30588236]\n",
      "   [0.10588235 0.14901961 0.16862746]]]\n",
      "\n",
      "\n",
      " [[[0.3254902  0.3137255  0.3764706 ]\n",
      "   [0.25490198 0.27058825 0.3647059 ]\n",
      "   [0.44705883 0.3882353  0.38039216]\n",
      "   ...\n",
      "   [0.8235294  0.78039217 0.7921569 ]\n",
      "   [0.5764706  0.54509807 0.57254905]\n",
      "   [0.3372549  0.3137255  0.35686275]]\n",
      "\n",
      "  [[0.5372549  0.52156866 0.57254905]\n",
      "   [0.27058825 0.28627452 0.37254903]\n",
      "   [0.41960785 0.3647059  0.36078432]\n",
      "   ...\n",
      "   [0.7411765  0.69803923 0.70980394]\n",
      "   [0.76862746 0.7372549  0.7647059 ]\n",
      "   [0.7254902  0.69803923 0.7411765 ]]\n",
      "\n",
      "  [[0.5764706  0.54509807 0.5764706 ]\n",
      "   [0.36078432 0.36862746 0.44313726]\n",
      "   [0.41960785 0.36862746 0.36862746]\n",
      "   ...\n",
      "   [0.7254902  0.68235296 0.69803923]\n",
      "   [0.8392157  0.8039216  0.8352941 ]\n",
      "   [0.7921569  0.7647059  0.80784315]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10588235 0.17254902 0.37254903]\n",
      "   [0.1254902  0.19215687 0.38431373]\n",
      "   [0.14509805 0.19215687 0.3764706 ]\n",
      "   ...\n",
      "   [0.2509804  0.35686275 0.5294118 ]\n",
      "   [0.34509805 0.47058824 0.64705884]\n",
      "   [0.22745098 0.36862746 0.5647059 ]]\n",
      "\n",
      "  [[0.16078432 0.21960784 0.38431373]\n",
      "   [0.14117648 0.19607843 0.3647059 ]\n",
      "   [0.10588235 0.14117648 0.32156864]\n",
      "   ...\n",
      "   [0.16862746 0.22745098 0.38431373]\n",
      "   [0.30980393 0.4        0.57254905]\n",
      "   [0.24705882 0.35686275 0.5568628 ]]\n",
      "\n",
      "  [[0.12156863 0.16862746 0.3137255 ]\n",
      "   [0.11764706 0.16078432 0.31764707]\n",
      "   [0.14901961 0.19215687 0.3647059 ]\n",
      "   ...\n",
      "   [0.14117648 0.15294118 0.30588236]\n",
      "   [0.10196079 0.13725491 0.31764707]\n",
      "   [0.11372549 0.16862746 0.36862746]]]] [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_directory_forged(directory, target_size=(img_height, img_width)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        path = os.path.join(directory, filename)\n",
    "        label = 0 \n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        img = img.astype('float32') / 255.0\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "forged_images,forged_labels = load_images_from_directory_forged(forged_path, target_size=(img_height, img_width))\n",
    "print(forged_images,forged_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6500, 224, 224, 3)\n",
      "(6500, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(real_images.shape)\n",
    "print(forged_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Define your data generators\n",
    "train_datagen = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',  # assuming binary classification\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "images.append(real_images)\n",
    "labels.append(real_labels)\n",
    "\n",
    "images.append(forged_images)\n",
    "labels.append(forged_labels)\n",
    "\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "images = np.concatenate(images, axis=0)\n",
    "\n",
    "print(labels)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(zip(images, labels))\n",
    "np.random.shuffle(dataset)\n",
    "shuffled_images, shuffled_labels = zip(*dataset)\n",
    "\n",
    "shuffled_images = np.array(shuffled_images)\n",
    "shuffled_labels = np.array(shuffled_labels)\n",
    "\n",
    "print(shuffled_labels)\n",
    "print(shuffled_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "\n",
    "def build_generator(latent_dim=100, img_height = 224, img_width = 224):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128 * 16 * 16, input_dim=latent_dim))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Reshape((16, 16, 128)))\n",
    "    target_shape = (img_height // 4, img_width // 4)  # Target size after upsampling\n",
    "    model.add(layers.UpSampling2D())\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.UpSampling2D())\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.UpSampling2D())\n",
    "    model.add(layers.Conv2D(3, (3, 3), padding='same', activation='sigmoid'))\n",
    "\n",
    "    # Adjust channels to 3 for RGB\n",
    "    return model\n",
    "\n",
    "def build_discriminator(img_height=128, img_width=128):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), input_shape=(img_height, img_width, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_gan_model(generator, discriminator, latent_dim=100):\n",
    "    discriminator.trainable = False  # Freeze the discriminator during combined model training\n",
    "\n",
    "    gan_input = layers.Input(shape=(latent_dim,))\n",
    "    generated_image = generator(gan_input)\n",
    "    print(generated_image.shape)\n",
    "    gan_output = discriminator(generated_image)\n",
    "\n",
    "    gan_model = models.Model(gan_input, gan_output)\n",
    "    gan_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "    return gan_model\n",
    "\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "407/407 [==============================] - 52s 127ms/step - loss: 0.6659 - accuracy: 0.5945\n",
      "Epoch 2/50\n",
      "407/407 [==============================] - 52s 127ms/step - loss: 0.6151 - accuracy: 0.6589\n",
      "Epoch 3/50\n",
      "407/407 [==============================] - 51s 126ms/step - loss: 0.5190 - accuracy: 0.7425\n",
      "Epoch 4/50\n",
      "407/407 [==============================] - 51s 126ms/step - loss: 0.4254 - accuracy: 0.8017\n",
      "Epoch 5/50\n",
      "407/407 [==============================] - 52s 127ms/step - loss: 0.3456 - accuracy: 0.8458\n",
      "Epoch 6/50\n",
      "407/407 [==============================] - 52s 128ms/step - loss: 0.2760 - accuracy: 0.8838\n",
      "Epoch 7/50\n",
      "407/407 [==============================] - 53s 130ms/step - loss: 0.2278 - accuracy: 0.9052\n",
      "Epoch 8/50\n",
      "407/407 [==============================] - 51s 125ms/step - loss: 0.2022 - accuracy: 0.9186\n",
      "Epoch 9/50\n",
      "407/407 [==============================] - 51s 124ms/step - loss: 0.1797 - accuracy: 0.9302\n",
      "Epoch 10/50\n",
      "407/407 [==============================] - 51s 124ms/step - loss: 0.1537 - accuracy: 0.9395\n",
      "Epoch 11/50\n",
      "407/407 [==============================] - 51s 126ms/step - loss: 0.1471 - accuracy: 0.9458\n",
      "Epoch 12/50\n",
      "407/407 [==============================] - 51s 125ms/step - loss: 0.1311 - accuracy: 0.9509\n",
      "Epoch 13/50\n",
      "407/407 [==============================] - 51s 125ms/step - loss: 0.1169 - accuracy: 0.9558\n",
      "Epoch 14/50\n",
      "407/407 [==============================] - 52s 128ms/step - loss: 0.1193 - accuracy: 0.9548\n",
      "Epoch 15/50\n",
      "407/407 [==============================] - 51s 125ms/step - loss: 0.1088 - accuracy: 0.9600\n",
      "Epoch 16/50\n",
      "407/407 [==============================] - 52s 128ms/step - loss: 0.0995 - accuracy: 0.9630\n",
      "Epoch 17/50\n",
      "407/407 [==============================] - 52s 128ms/step - loss: 0.1006 - accuracy: 0.9623\n",
      "Epoch 18/50\n",
      "407/407 [==============================] - 53s 129ms/step - loss: 0.0939 - accuracy: 0.9667\n",
      "Epoch 19/50\n",
      "407/407 [==============================] - 52s 127ms/step - loss: 0.1008 - accuracy: 0.9671\n",
      "Epoch 20/50\n",
      "407/407 [==============================] - 52s 128ms/step - loss: 0.0972 - accuracy: 0.9679\n",
      "Epoch 21/50\n",
      " 66/407 [===>..........................] - ETA: 41s - loss: 0.0587 - accuracy: 0.9763"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m      2\u001b[0m discriminator \u001b[38;5;241m=\u001b[39m build_discriminator()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_datagen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_datagen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Image_Forgery_Detection\\my_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Image_Forgery_Detection\\my_venv\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Image_Forgery_Detection\\my_venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Image_Forgery_Detection\\my_venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Image_Forgery_Detection\\my_venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\Image_Forgery_Detection\\my_venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Image_Forgery_Detection\\my_venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Image_Forgery_Detection\\my_venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Image_Forgery_Detection\\my_venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "discriminator.fit(train_datagen, epochs=50, steps_per_epoch=len(train_datagen),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model.save('forgery_detection_gan_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.save('forgery_discriminator_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "generated_image = generator.predict(np.random.normal(0, 1, (batch_size, 100)))\n",
    "\n",
    "plt.imshow(generated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.fit(images,labels,epochs = 25 , verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
